\section{Methods}
\label{sec:methods}

This section provides a description of the simulator and the implemented features.
First, it introduces the framework and its workflow.
Then, it details agent modeling, their initialization and behavior.
Finally, the implemented opinion models are described, including the impact of agent behavior on their opinions.

\subsection{Simulation workflow}
This work is based on Y, a social media digital twin \cite{rossetti2024ysocialllmpoweredsocial}.
Algorithm \ref{alg:workflow} describes the base workflow of the simulations. 
It preserves the core implementation, and extends it to include the opinion update at the end of the day.
The framework can be customized through a configuration file, which allows the specification of many parameters to model the desired environment.

The population of agents is initially created without any predefined network.
Throughout the simulation, agents can form and remove connections, allowing the network structure to emerge and evolve.

In each round, a number of active agents is sampled, according to the hourly activity defined in the configuration file.
Agents then perform their action, detailed in the next subsection, and eventually reply to received mentions.
%At the end of each day, a subsample of users are selected to follow a recommended user.
Finally, agents are asked to update their opinion on the topics they discussed during the day.

The original framework also allows to manage a percentage of agents that can leave or join the platform daily. This is omitted in the algorithm, as this study only focuses on those users who remain subscribed to the platform for the whole simulated time frame. 

\begin{algorithm}
\caption{Simulation workflow}
\label{alg:workflow}
\begin{algorithmic}[1]
\COMMENTLINE{Agents creation and initialization}
\STATE $agents \gets create\_population()$

\COMMENTLINE{Simulation loop}
\FOR{$day \in n\_days$}
    \FOR{$round \in n\_rounds$}
        \COMMENTLINE{Sample agents active in the current round}
        \STATE $n\_actives \gets len(agents) \times hourly\_activity[round]$
        \STATE $active\_agents \gets sample(agents, n\_actives)$ 
        \FOR{$agent \in active\_agents$}
            \COMMENTLINE{Perform actions}
            \STATE $agent.select\_action()$
            \STATE $agent.reply\_mentions()$
        \ENDFOR
    \ENDFOR

    \COMMENTLINE{Add new connections}
    \STATE $sel\_agents \gets sample(daily\_actives, percentage\_daily\_follows)$
    \FOR{$agent \in sel\_agents$}
        \STATE $agent.search\_and\_follow()$
    \ENDFOR

    \COMMENTLINE{Opinion update}
    \FOR{$agent \in daily\_actives$}
        \STATE $agent.update\_opinions()$
    \ENDFOR

\ENDFOR
\end{algorithmic}
\end{algorithm}



\subsection{Agents}
% Intro about the complexity of agents and the ability of LLMs to impersonate them (?)

\subsubsection{Initialization}
Agents in Y are initialized with various profile features, which contributes to the creation of users with a detailed description and characterization.

% Random data and personality
Some dimensions are randomly sampled: name, surname, email, password and personality.
Specifically, the personality is defined according to the Five-Factor Model \cite{barrick1991bigfive, McCrae1992}, mostly known as the Big Five model. 
Users can be either high or low in each dimension, as described Table \ref{tab:susceptibility}, which leads to at most 32 distinct personality types.

\medskip
% Age and gender
In this study, the age and gender of agents are randomly assigned, weighted according to 2024 Twitter statistics \cite{statista2024twitter}. Only the data for people aged 18 and above were considered, and the maximum age is set to 60, in line with the value in the original configuration of Y.

% Nationality and interests
Moreover, all agents are set with Italian nationality, in order to guarantee coherency with the context of the presented case study, and they are configured with four interests, corresponding to the four topics analyzed in this study: \textit{Immigration}, \textit{Nuclear energy}, \textit{Civil rights}, \textit{Reddito di Cittadinanza}.

\medskip
% Attributes from real data
To make the users even more realistic, some attributes have been initialized starting from real-world data, based on the dataset presented by \citet{pierri2023ita}. This includes Twitter posts collected around the Italian political elections in 2022.
Specifically, the attributes initialized from the dataset in this work are: the political leaning, the toxicity in writing posts and comments, and the activity level.
The activity is computed by converting the number of tweets written by each user into a continuous value in the range $[0,1]$, using the following logarithmic normalization:

\[
activity_x = \min\left( \frac{\log(1 + n\_posts_x)}{\log(1 + N_{99.5})},\ 1.0 \right)
\]

where $n\_posts_x$ is the number of posts written by user $x$, and $N_{99.5}$ is the 99.5th percentile, used to mitigate the impact of outliers.


% Agent roles and prompts
\medskip
In this framework, the orchestration of agents to simulate multi-agent conversation is enabled by AutoGen \cite{pyautogen0.2.31, wu2023autogenenablingnextgenllm}.
LLM-agents are initialize with the assigned profile, before performing any action. 

The prompt to initialize the agent with its role is the following: 
\input{prompts/agent_roleplay}


\subsubsection{Behavior}
When an agent is active, one among the following actions is performed:
\begin{itemize}
    \item \textbf{post}: writing a tweet about a given topic.
    \item \textbf{comment}: after reading a given conversation, the agent is asked to comment it; he can then decide to add a reaction (\textit{like} or \textit{dislike}), and \textit{follow} (\textit{unfollow}) its author.
    \item \textbf{read}: after reading a given tweet, the agent can decide to add a reaction (\textit{like} or \textit{dislike}) and \textit{follow} (\textit{unfollow}) its author, without adding any contribution to the conversation.
\end{itemize}

\medskip
% Select action
In the original implementation of Y, the agents were responsible of choosing which action to perform.
This work instead uses the agent's posting and commenting activity (each in the range $[0,1]$) as probabilities. If their sum is less then 1, the remaining probability is assigned to the \textit{read} action.
This implementation allows to model the agent behavior leveraging the real data available in this study.

% <one prompt example>

All the prompts with the instructions to perform an action can be found in Appendix \ref{app:prompt_actions}.

% Topic descriptions
\medskip
Each time a topic is assigned to the agent, a description is also provided.
This is done for two reasons: to provide the LLM with the necessary background knowledge (especially regarding the 2022 Italian political views), and to outline the main stances associated with the topic, ensuring consistency and clarity in the simulation.

The following are the topic descriptions provided:

\begin{itemize}
    \item \textbf{Reddito di cittadinanza}:
        \begin{tcolorbox}[prompt]
            A state subsidy for people living in poverty, designed to ensure a minimum standard of living and promote employment integration. Supporters believe reddito di cittadinanza is a necessary tool for social protection and inclusion; opponents are concerned about potential work disincentives and system abuses. The most radical want to abolish it, others aim to reform it.
        \end{tcolorbox}

    \item \textbf{Immigration}:
        \begin{tcolorbox}[prompt]
            Debates focus on border control, bilateral agreements, and managing irregular migration. Supporters advocate for inclusive immigration policies, humanitarian protection and integration; opponents prioritize national security and strict border enforcement.
        \end{tcolorbox}

    \item \textbf{Nuclear energy}:
        \begin{tcolorbox}[prompt]
            Debates focus on whether to include it in the energy mix. Supporters cite energy security; opponents stress risks, costs, and favor renewables.
        \end{tcolorbox}

    \item \textbf{Civil rights}:
        \begin{tcolorbox}[prompt]
            Covers gender equality, LGBTQIA+ rights and family structure. Supporters support expanding protections for LGBTQIA+ individuals, gender equality, and inclusive definitions of family; opponents prioritize traditional family models and may reject changes to marriage, parenting, or gender roles.
        \end{tcolorbox}
    
\end{itemize}



\subsubsection{Misinformation agents}
This work extends the agents modeled by Y, by introducing some special agents, designed to generate misinformation.
These agents are not bots nor coordinated agents: they are designed as all other normal agents, and they are prompted with a profile including demographics and personality.

% Misinformation content
The main difference is that they are encouraged to generate misleading content supporting their views:

\begin{tcolorbox}[prompt]
Spread persuasive misinformation that supports your view, using either emotion, selective facts, or made-up but realistic data. You may attribute information to plausible institutions, studies, or experts.
\end{tcolorbox}

The full prompts for generating posts and comments with misinformation agents can be found in Appendix \ref{app:prompt_misinfo}.

\medskip
% Coalition assignment, toxicity and activity generation
Another difference is that these agents are not directly initialized with the data of real users.
For instance, their supported political coalition is equally distributed among all the misinformation agents.
Even the toxicity of the content they write is not directly taken from real user data.
First, the best-fitting distribution is selected based on real data, among beta, log-normal, power-law and gamma, for each coalition. Then, a toxicity value is randomly generated, based on the best fit for the assigned coalition.
Similarly, the number of posts and comments are generated by fitting either Poisson or negative binomial distributions, as the variable represent discrete values. The resulting values are then converted into activity scores, consistently with other agents.


\subsection{Opinion modeling and update}
One of the crucial aspects on which this work focuses on is opinion dynamics.
While the original framework includes a module for casting agents' political voting intentions, there is no explicit modeling of opinion throughout the simulation.
Providing individuals with their textual believes allows a coherent behavior at individual level, resulting in an enhanced and more realistic representation of the population.

In this work, the opinion is modeled as a numerical score that ranges from $-1$ (strongly opposed) to $+1$ (strongly supported).

The models implemented can be grouped into two categories.
The first one includes some basic score aggregation and various known opinion models, to mathematically represent the evolution of agents' believes.
The second solution employs LLMs, leveraging their ability to impersonate the user, reason, and express their views in a textual format.

%


\subsubsection{Mathematical modeling}
% Median, weighted mean
A straightforward approach to estimate an individual's opinion is to compute the median or the weighted mean of previous obtained scores.
This is particularly useful when opinions are externally assigned, and a summary representation is needed.

\medskip
% Friedkin-Johnsen
A model implemented in this work is the one presented by \citet{friedkin_1990}, which considers both the individuals' initial opinion and those of their neighbors, weighted by a susceptibility value:
\[
x_i(t + 1) = (1 - \lambda_i) x_i(0) + \lambda_i   \sum_{j \in N_i(t)} w_{ij} x_j(t)
\]
where $x_i(t)$ is the opinion of individual $i$ at time $t$, $N_i$ is the set of following users, $\lambda_i$ is the user's susceptibility to other users, and $w_{ij}$ is the impact user $j$ has on $i$. 

Note that in this first implementation only the followed users are considered neighbors, and they all have the same weight.

% Susceptibility score
The susceptibility $\lambda$ is a value in the range $[0,1]$, $0$ meaning \textit{not susceptible}, $1$ \textit{highly susceptible}.
This approach relies on the idea that personality traits have an impact on social influence \cite{oyibo2019personality}, and it's therefore here computed for each individual as the mean of the scores for each assigned trait, visible in Table \ref{tab:susceptibility}.

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|c|}
\hline
\textbf{Trait} & \textbf{Trait level} & \textbf{Description} & \textbf{Susceptibility score} \\
\hline
\multirow{2}{*}{Neuroticism}       
  & High & sensitive/nervous         & 0.9 \\
  & Low & resilient/confident        & 0.1 \\
\hline
\multirow{2}{*}{Openness to experience}          
  & High & inventive/curious         & 0.2 \\
  & Low & consistent/cautious        & 0.6 \\
\hline
\multirow{2}{*}{Conscientiousness} 
  & High & efficient/organized       & 0.2 \\
  & Low & extravagant/careless       & 0.6 \\
\hline
\multirow{2}{*}{Extroversion}      
  & High & outgoing/energetic        & 0.5 \\
  & Low & solitary/reserved          & 0.5 \\
\hline
\multirow{2}{*}{Agreeableness}     
  & High & friendly/compassionate    & 0.5 \\
  & Low & critical/judgmental        & 0.5 \\
\hline
\end{tabular}
\caption{The table shows the susceptibility scores assigned to each personality trait. Values range from $0$ (not susceptible) to $1$ (highly susceptible).}
\label{tab:susceptibility}
\end{table}

\medskip
% State-dependent Friedkin-Johnsen
A state-dependent version of the previous model considers the influence of the current opinion rather than the initial one \cite{Ye2018Opinion}:
\[
x_i(t + 1) = (1 - \lambda) x_i(t) + \lambda_i  \sum_{j \in N_i(t)} w_{ij} x_j (t)
\]

Equivalently to the previous solution, all followed users can be assigned the same weight.
Alternatively, it's possible to also include in the set of neighbors all users the agent has interacted with since the last opinion update, through reactions. In this case, their weights depend on the type (and frequency) of the interactions, where the scores of a single interaction, later normalized, are assigned as follows: 
\begin{itemize}
    \item \textbf{follow}: $+1$
    \item \textbf{like}: $+0.2$
    \item \textbf{dislike}: $-0.2$
\end{itemize}



\subsubsection{LLM-based opinion update}
Another solution implemented in this work to model the opinion dynamics is to directly ask LLM agents to update the opinion of the users they are impersonating.

Agents are initialized with the opinions of their supported political leaning. During the simulation, they act coherently with their ideas, and finally evolve their own views according to their daily interactions.

Agents are given their profile, the description of the topics to update, their supported coalition believes and their own current ideas on the topics, and a the memory of their actions since last opinion update.
Specifically, the memory tracks the posts a user reads and writes, the replies, the reactions, and whether there are changes in the follow status with another user, after interacting. 

With all this knowledge, the LLMs are prompted to provide their updated opinion in a textual format.
They are also asked to assign a stance to each of the updated topics, choosing among a set of given labels. This allows to easily extract a numerical score, according to the conversion visible in Table \ref{tab:stance}, and is useful for later analysis.

\begin{table}[h]
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Stance} & \textbf{Score} \\
\hline
STRONGLY OPPOSED   & $-1.0$ \\
OPPOSED            & $-0.5$ \\
NEUTRAL            & $0$ \\
SUPPORTIVE         & $+0.5$ \\
STRONGLY SUPPORTIVE & $+1.0$ \\
\hline
\end{tabular}
\caption{Mapping agents' stance from textual labels to numerical scores.}
\label{tab:stance}
\end{table}

% Bias instruction
\medskip
The prompt to update the opinion also includes a confirmation bias. This allows to get a greater opinion fragmentation, as discussed in previous studies \cite{chuang2024simulatingopiniondynamicsnetworks}.

The presented research proposes two levels of bias, in order to to differentiate the behavior of misinformation agents from the rest of the population.
The base bias, proposed by \cite{Liu_2024}, is the following:

\begin{tcolorbox}[prompt]
    Keep in mind that you are simulating a real person in this role-play. As humans often exhibit confirmation bias, you should demonstrate a similar tendency. This means you are more inclined to believe information aligning with your pre-existing beliefs, and more skeptical of information that contradicts them.
\end{tcolorbox}


Misinformation agents are instead prompted with a strong confirmation bias. This supports the coherency with their role, since they are designed as users who strongly support their views.
The instruction, presented by \cite{chuang2024simulatingopiniondynamicsnetworks}, is shown below:

\begin{tcolorbox}[prompt]
    Remember, you are role-playing as a real person. You have a strong confirmation bias. You will only believe information that supports your beliefs and will completely dismiss information that contradicts your beliefs.
\end{tcolorbox}

The full prompt for the opinion update can be found in Appendix \ref{app:prompt_opinion}.