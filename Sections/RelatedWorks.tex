\section{Related works}
\label{sec:relatedworks}

% <intro>

\subsection{Simulating Social Networks}

Social simulations have been developed as a tool to study the behavior of groups of people, addressing the challenges posed by the nonlinear effects of individual interactions \cite{squazzoni2014socialsimulation}.
Agent-Based Modeling (ABM) focuses on the dynamics of agents at the local level, and shows that these simple interactions can recreate complex social phenomena and group behavior \cite{macy2002abm}.
Specifically, ABM allows researchers to relate social phenomena at both micro and macro level, showing the causal relation between individual behavior and the structural properties of the network. \cite{squazzoni2014socialsimulation}.
The main limitations historically highlighted are that individuals follow simple rules \cite{conte2014agent}, and that they lack the capacity to reason and engage in social interaction.\cite{törnberg2023evaluate}
However, the recent advancements in LLMs offer a new opportunity to overcome the drawbacks of classical ABM systems, as they enable the generation of agents capable of engaging in realistic conversations and reproducing believable human-like behavior \cite{park2023genagents}.

Several recent works have explored the potential of LLM agents in social network simulated environments. Below, we discuss three relevant simulators.
\medskip

% Törnberg
\citet{törnberg2023evaluate} simulated three social media platforms, each with a specific content recommendation algorithm, to evaluate how alternative news feed algorithms impact the quality of online conversation, while increasing the interaction between opposing views.

The agents in the simulation, powered by LLMs, are individuals initialized with demographic characteristics, political leaning, interests and attitudes, taken from the 2020 American National Election Study (ANES).
The first platform promotes the most popular posts by following users, while the second one suggests the globally most popular posts. Both algorithms resulted in reduced cross-party interactions and increased toxicity.
In contrast, the third system introduces a "bridging" algorithm, which recommends the posts popular among users with opposing political views. The result is that the interactions were the least toxic, more constructive, and with more inter-partisan interactions.

This finding highlights the direct impact that content recommender systems have on the quality of online discourse.
\medskip

% S3
In the social network simulator proposed by \citet{gao2023s3socialnetworksimulationlarge}, the LLM agents keep a memory pool with the most relevant content they posted. This enhances the agents' cognitive coherence and realism, making their behavior and attitudes more realistic.
The system was then evaluated using real-world social network data on two levels: the considered The system was evaluated using real-world social network data on two levels: at the individual level, aspects such as emotions, attitude, and content generation were considered; at the population level, the focus was on information propagation, and the spread of emotions and attitudes. 
Results show that the system achieved promising accuracy, and that it was able to reproduce complex real-world trends.

\medskip
% YSocial
\citet{rossetti2024ysocialllmpoweredsocial} introduced Y, a social media digital twin, a system designed to digitally replicate a real-world system to allow analysis, simulation and experimentation in a controlled environment.
The users of these simulations are LLM agents, and they can perform all the common actions available on the most popular social media, including posting, commenting, replying, reacting and following other users. Other modules also allow the integration of images.
User profiles are enriched with attributes including their interests, political leaning, demographic data and personality, which is defined according to the Big Five model \cite{McCrae1992}.
To make the simulations even more realistic, Y also includes the possibility of adding external input to the simulation. Specifically, users can share news gathered from selected websites, provided through RSS (Really Simple Syndication) feeds.
Moreover, Y includes the implementation of various recommender and ranking algorithms to promote specific content or users. This enables further study of the impact the algorithmic curation has on online conversations and users' behavior. This expands the approach of \citet{törnberg2023evaluate}, by offering a more flexible and realistic simulation framework.



\subsection{Simulating misinformation with LLM agents}
% <Misinfo intro>

\citet{williams2025hqdisinformation} show that LLMs are able to generate high-quality content in the context of disinformation campaigns, with a high level of humanness that makes it undistinguishable from human content for more than 50\% of the times.

\citet{liu2024tinyslipgiantleap} studies the evolution of fake news and its spread in social media, by making simulations of network structures with LLM agents.
The agents are divided into four categories: spreaders, commentators, diffusors, bystanders. These distinct roles define how agents operate towards the posts they read and write.
The research focused on different topics, and the main outcome is that political fake news spread faster than other types of topics.

\citet{hu2025simulatingrumorspreadingsocial} simulate networks with LLM agents to study the spread of rumors. They highlight that the network structure and the individual personalities impact the rumor spread.





\subsection{Opinion Dynamics}
%<intro> Multiple ways throughout various studies to model opinion dynamics, which is not trivial.

% Mathematical models
DeGroot is a well-known opinion dynamic model, which considers that individuals are susceptible to other people's opinions. For this reason, each opinion is modeled as a weighted average of the neighbors' opinions.

The Friedkin-Johnsen model \cite{friedkin_1990} extends the DeGroot model by introducing a component to consider the "stubborness" of the individual to his own initial idea. 

In another variant, the opinion of individuals is influenced by both their own current opinion, and that of the neighbors \cite{Ye2018Opinion, Liu_2018}. This discrete-time solution is equivalent to the Friedkin-Johnsen model, but the stubbornness is on the current opinion, rather then the initial one.


% LLMs
Recently, the advent of LLMs introduced a new way to simulate and study opinion dynamics.
Their human-like reasoning capability allows a realistic simulation of human behavior, also enabling opinion explanation in textual format.

\citet{cau2025languagedrivenopiniondynamicsagentbased} experimented simulations where agents had to discuss in pairs about the Ship of Theseus paradox.
The opinion is a discrete value within the range 0-6, which is updated with a +- 1,  to reinforce or to discuss their previous opinion, according to whether they were convinced by their partner or not.
The results show that LLMs tend to agree with a given statement and interacting partners. However, the agents considered are very simple, as they lack personality and demographic characterization.

\citet{chuang2024simulatingopiniondynamicsnetworks} had a set of users with defined demographic data and political leaning, interacting in a dyadic setting. Users replicate to another user's post by explaining their opinion in textual format, which is then converted into a numerical score by an opinion classifier.
This study reveals that LLMs have a tendency to converge towards accurate information, therefore introducing confirmation bias is essential to better resemble human behavior and opinion dynamics.

\citet{Liu_2024} simulated user interactions in presence of fake news. Users are initialized with realistic personas, including personality traits and a memory model. Their opinion is a textual description, shared in a tweet format. 
Users are exposed every day with random tweets from other users, there is no social graph modeling, nor content distribution algorithm.

\citet{piao2025emergencehumanlikepolarizationlarge} studied the opinion dynamics on thousands of LLM agents, about different topics. They underline that LLMs are capable of reproducing human behavior and phenomenon. They also noticed that LLMs tent to reach a consensus on fact-based topics (such as the flat Earth theory), while they develop a polarization pattern on political topics.
To get a score out of the agents' opinions, they ask the agents to evaluate their political leaning, which is then converted to a numerical format.

\citet{gao2023s3socialnetworksimulationlarge} models the attitude towards a topic with a Markov model in a binary spectrum, and uses LLMs to evaluate the transitions. There are multiple factors that impact the change in the opinion of an individual, such as the current attitude, the profile and the messages received.


