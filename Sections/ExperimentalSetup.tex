\section{Experimental setup}
\label{sec:experiments}


To study the evolution of opinions and the impact of misinformation in a simulated social context, various multi-agent simulations have been run, each lasting 21 virtual days.
The population was composed of 100 agents, configured according to the approach described in the previous section, therefore assigning each agent a profile and personality.
This setup allows to obtain an heterogeneous population of users with different opinions and communication styles.

Regarding the frequency of activity of agents during the day, the simulations used the hourly activity proposed in the original Y system, which is based on a statistical fitting on real data on Bluesky Social \cite{rossetti2024ysocialllmpoweredsocial, failla2024}.
This guarantees a realistic temporal distribution of daily interactions, coherently with a real social network.

\medskip
The LLM used by agents is \textit{artifish/llama3.2-uncensored}, available on \textit{Ollama} platform. 
This has been chosen because it's open source and uncensored.
This aspect is crucial when working with potentially controversial topics, such as political discussions or extremist stances.
In fact, other models with the ethical filter tend to refuse to generate content about sensible topics, or avoid expressing a more extremist opinion.
Using an uncensored LLM allows therefore to produce contents closer to real-world language, even on controversial arguments.
To encourage diversity in the generated contents, the temperature has been set to 0.9, balancing variety and coherency with the assigned agent profile.

\medskip
During the experimentation phase, various conditions have been tested, to evaluate hoe some factors can influence the behavior of agents.
Specifically, the variables considered are:
\begin{itemize}
    % TODO: remove or simplify, explained in methods
    \item \textbf{Content recommender systems}: Y platform has the possibility to define how contents are selected and provided to users.
    This mechanism has a direct impact on the interactions and therefore on the evolution of the simulation.
    Among the various algorithms proposed by the framework, the following have been adopted in this work:
        \subitem \textit{ReverseChronoFollowersPopularity}: recommends recent content from followed users, sorted by their popularity. A specified percentage of content comes from non-followed users, to guarantee exposure to different views.
        \subitem \textit{ContentRecSys}: randomly selects a subset of the content published on the platform.
    \item \textbf{Misinformation level}: this work integrated in the existing framework misinformation agents, who publish misleading content. 
    Various levels of misinformation have been tested, to analyze whether and how it impacts the evolution of the social system.
        \subitem \textbf{0\%}: scenario with no misinformation, useful as baseline.
        \subitem \textbf{5\%}: low misinformation level, mimics an occasional exposure to misinformation.
        \subitem \textbf{10\%}: medium level, the exposure is moderate but significant.
        \subitem \textbf{50\%} extremely high exposure, unrealistic but useful to observe extreme dynamics.
\end{itemize}

These conditions make it possible to explore both realistic and extreme scenarios, in order to have a complete view of the effect of the considered variables.

\medskip
Each scenario, corresponding to a specific combination of misinformation level and disinformation, has been run between 10 and 20 times, each time with new population of agents.
This approach guarantees statistical robustness of results and analyze general trends, reducing the influence of randomness. 
